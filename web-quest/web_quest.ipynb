{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWpPH+JCM9GVz+/ma0fWSw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedmuneeb321/lanchain-practise/blob/main/web-quest/web_quest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px-BX1JqslXx"
      },
      "outputs": [],
      "source": [
        "%pip install langchain python-dotenv ipykernel langchain-community pypdf bs4 arxiv pymupdf wikipedia langchain-text-splitters langchain-openai chromadb sentence_transformers langchain_huggingface faiss-cpu langchain_chroma duckdb pandas openai langchain-groq duckduckgo_search==5.3.1b1 mysql-connector-python SQLAlchemy validators==0.28.1 youtube_transcript_api unstructured pytube numexpr huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=userdata.get('OPENAI_API_KEY')\n",
        "## Langsmith Tracking\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=userdata.get(\"LANGCHAIN_PROJECT\")"
      ],
      "metadata": {
        "id": "T7iEZeVlty4t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain"
      ],
      "metadata": {
        "id": "4KZGo9hrt0gA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "\n",
        "loader=WebBaseLoader(\"https://python.langchain.com/v0.1/docs/modules/chains/\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "isMKMFC_uVH8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data\n",
        "text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
        "documents = text_spliter.split_documents(docs)"
      ],
      "metadata": {
        "id": "QHC_U9qMukKz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set embedding\n",
        "\n",
        "embeddings=OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "ZNedJSQou5oS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "db = FAISS.from_documents(documents, embeddings)\n"
      ],
      "metadata": {
        "id": "RPFzmFsovQUc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever=db.as_retriever()"
      ],
      "metadata": {
        "id": "oe0k2O-Fw4DF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm=ChatOpenAI(model=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "mtgBa3uEvXL_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Respond to the following question using only the information given in the context provided:\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "T9civnAbvdvx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup chain\n",
        "document_chain = create_stuff_documents_chain(llm,prompt)\n",
        "retrieval_chain = create_retrieval_chain(retriever,document_chain)\n",
        "\n"
      ],
      "metadata": {
        "id": "IIxap4hvwGx6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=retrieval_chain.invoke({\"input\":\"What is LCEL\"})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyJRJQvExSad",
        "outputId": "0920a8ff-90af-43d5-e466-997a667a27b4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'What is LCEL', 'context': [Document(metadata={'source': 'https://python.langchain.com/v0.1/docs/modules/chains/', 'title': 'Chains | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL.', 'language': 'en'}, page_content=\"LCEL is great for constructing your chains, but it's also nice to have chains used off the shelf. There are two types of off-the-shelf chains that LangChain supports:Chains that are built with LCEL. In this case, LangChain offers a higher-level constructor method. However, all that is being done under the hood is constructing a chain with LCEL. [Legacy] Chains constructed by subclassing from a legacy Chain class. These chains do not use LCEL under the hood but are the standalone classes.We are working on creating methods that create LCEL versions of all chains. We are doing this for a few reasons.Chains constructed in this way are nice because if you want to modify the internals of a chain you can simply modify the LCEL.These chains natively support streaming, async, and batch out of the box.These chains automatically get observability at each step.This page contains two lists. First, a list of all LCEL chain constructors. Second, a list of all legacy Chains.LCEL Chains‚ÄãBelow is a\"), Document(metadata={'source': 'https://python.langchain.com/v0.1/docs/modules/chains/', 'title': 'Chains | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL.', 'language': 'en'}, page_content='box.These chains automatically get observability at each step.This page contains two lists. First, a list of all LCEL chain constructors. Second, a list of all legacy Chains.LCEL Chains‚ÄãBelow is a table of all LCEL chain constructors. Table columns:Chain Constructor: The constructor function for this chain. These are all methods that return LCEL Runnables. We also link to the API documentation.Function Calling: Whether this requires OpenAI function calling.Other Tools: Other tools (if any) used in this chain.When to Use: Our commentary on when to use this chain.Chain ConstructorFunction CallingOther ToolsWhen to Usecreate_stuff_documents_chainThis chain takes a list of documents and formats them all into a prompt, then passes that prompt to an LLM. It passes ALL documents, so you should make sure it fits within the context window of the LLM you are using.create_openai_fn_runnable‚úÖIf you want to use OpenAI function calling to OPTIONALLY structured an output response. You may pass'), Document(metadata={'source': 'https://python.langchain.com/v0.1/docs/modules/chains/', 'title': 'Chains | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL.', 'language': 'en'}, page_content=\"Skip to main contentA newer LangChain version is out! Check out the latest version.ComponentsIntegrationsGuidesAPI ReferenceMorePeopleVersioningContributingTemplatesCookbooksTutorialsYouTubev0.1Latestv0.2v0.1\\uf8ffü¶úÔ∏è\\uf8ffüîóLangSmithLangSmith DocsLangServe GitHubTemplates GitHubTemplates HubLangChain HubJS/TS Docs\\uf8ffüí¨SearchModel I/OPromptsChat modelsLLMsOutput parsersRetrievalDocument loadersText splittersEmbedding modelsVector storesRetrieversIndexingCompositionToolsAgentsChainsMoreComponentsThis is documentation for LangChain v0.1, which is no longer actively maintained.For the current stable version, see this version (Latest).CompositionChainsChainsChains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL. LCEL is great for constructing your chains, but it's also nice to have chains used off the shelf. There are two types of off-the-shelf chains that LangChain supports:Chains that are built with LCEL.\"), Document(metadata={'source': 'https://python.langchain.com/v0.1/docs/modules/chains/', 'title': 'Chains | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL.', 'language': 'en'}, page_content='Chains | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain')], 'answer': 'LangChain supports two types of off-the-shelf chains: those built with LCEL and legacy chains. LCEL chains benefit from easier modification of their internals, native support for streaming, async, and batch processing, as well as automatic observability at each step. Legacy chains, on the other hand, do not use LCEL and are standalone classes. LangChain is working on creating LCEL versions of all legacy chains for these advantages.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "8-sTevhBxWHb",
        "outputId": "5da5f550-67fb-4f01-838e-4eb723d13673"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'input': 'What is LCEL',\n",
              " 'context': [Document(metadata={'source': 'https://python.langchain.com/v0.1/docs/modules/chains/', 'title': 'Chains | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL.', 'language': 'en'}, page_content=\"LCEL is great for constructing your chains, but it's also nice to have chains used off the shelf. There are two types of off-the-shelf chains that LangChain supports:Chains that are built with LCEL. In this case, LangChain offers a higher-level constructor method. However, all that is being done under the hood is constructing a chain with LCEL. [Legacy] Chains constructed by subclassing from a legacy Chain class. These chains do not use LCEL under the hood but are the standalone classes.We are working on creating methods that create LCEL versions of all chains. We are doing this for a few reasons.Chains constructed in this way are nice because if you want to modify the internals of a chain you can simply modify the LCEL.These chains natively support streaming, async, and batch out of the box.These chains automatically get observability at each step.This page contains two lists. First, a list of all LCEL chain constructors. Second, a list of all legacy Chains.LCEL Chains‚ÄãBelow is a\"),\n",
              "  Document(metadata={'source': 'https://python.langchain.com/v0.1/docs/modules/chains/', 'title': 'Chains | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL.', 'language': 'en'}, page_content='box.These chains automatically get observability at each step.This page contains two lists. First, a list of all LCEL chain constructors. Second, a list of all legacy Chains.LCEL Chains‚ÄãBelow is a table of all LCEL chain constructors. Table columns:Chain Constructor: The constructor function for this chain. These are all methods that return LCEL Runnables. We also link to the API documentation.Function Calling: Whether this requires OpenAI function calling.Other Tools: Other tools (if any) used in this chain.When to Use: Our commentary on when to use this chain.Chain ConstructorFunction CallingOther ToolsWhen to Usecreate_stuff_documents_chainThis chain takes a list of documents and formats them all into a prompt, then passes that prompt to an LLM. It passes ALL documents, so you should make sure it fits within the context window of the LLM you are using.create_openai_fn_runnable‚úÖIf you want to use OpenAI function calling to OPTIONALLY structured an output response. You may pass'),\n",
              "  Document(metadata={'source': 'https://python.langchain.com/v0.1/docs/modules/chains/', 'title': 'Chains | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL.', 'language': 'en'}, page_content=\"Skip to main contentA newer LangChain version is out! Check out the latest version.ComponentsIntegrationsGuidesAPI ReferenceMorePeopleVersioningContributingTemplatesCookbooksTutorialsYouTubev0.1Latestv0.2v0.1\\uf8ffü¶úÔ∏è\\uf8ffüîóLangSmithLangSmith DocsLangServe GitHubTemplates GitHubTemplates HubLangChain HubJS/TS Docs\\uf8ffüí¨SearchModel I/OPromptsChat modelsLLMsOutput parsersRetrievalDocument loadersText splittersEmbedding modelsVector storesRetrieversIndexingCompositionToolsAgentsChainsMoreComponentsThis is documentation for LangChain v0.1, which is no longer actively maintained.For the current stable version, see this version (Latest).CompositionChainsChainsChains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL. LCEL is great for constructing your chains, but it's also nice to have chains used off the shelf. There are two types of off-the-shelf chains that LangChain supports:Chains that are built with LCEL.\"),\n",
              "  Document(metadata={'source': 'https://python.langchain.com/v0.1/docs/modules/chains/', 'title': 'Chains | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL.', 'language': 'en'}, page_content='Chains | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain')],\n",
              " 'answer': 'LangChain supports two types of off-the-shelf chains: those built with LCEL and legacy chains. LCEL chains benefit from easier modification of their internals, native support for streaming, async, and batch processing, as well as automatic observability at each step. Legacy chains, on the other hand, do not use LCEL and are standalone classes. LangChain is working on creating LCEL versions of all legacy chains for these advantages.'}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4u9KidgGzq6T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}